<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Hyunsik Jeon @ UC San Diego</title>
  
  <meta name="author" content="Hyunsik Jeon">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
<!--	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">-->
    <link rel="icon" type="image/png" href="images/UCSD.png?">
</head>

<body>
  <table style="width:100%;max-width:850px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:70%;vertical-align:middle">
              <p style="text-align:center">
                <name>Hyunsik Jeon</name><br>
                <affiliation>Postoctoral Researcher at UC San Diego</affiliation>
              </p>
              <p>
<!--                <span style="color: red;">I am actively seeking a full-time industrial research position starting in 2025!</span><br>-->
                I am a Postdoctoral Researcher at the <a href="https://cse.ucsd.edu">Dept. of Computer Science and Engineering</a> of UC San Diego, where I am working with <a href="https://cseweb.ucsd.edu/~jmcauley/">Prof. Julian McAuley</a>.
                I received my Ph.D. and M.Sc. from the Dept. of Computer Science and Engineering at Seoul National University, where I was advised by <a href="https://datalab.snu.ac.kr/~ukang/">Prof. U Kang</a>.
                I obtained my B.Sc. from the Dept. of Computer Science and Engineering at Hanyang University.
                My research interests lie in enhancing recommender systems, with a focus on more accurate, fair, and interactive recommendation solutions.
              </p>
              <p>
                <strong>Email:</strong> hyjeon (at) ucsd.edu, jeon185 (at) gmail.com
              </p>
              <p style="text-align:center">[
                <a href="data/resume.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.co.kr/citations?user=gSuQnSYAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://dblp.org/pid/207/7677.html">DBLP</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/jeon185">LinkedIn</a> &nbsp/&nbsp
                <a href="https://github.com/jeon185">GitHub</a>
                ]
              </p>
            </td>
            <td style="padding:2.5%;width:30%;max-width:30%">
              <img style="width:100%;max-width:100%" alt="profile photo" src="images/hyunsik6.png" class="hoverZoomLink">
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research Interests</heading>
              <ul>
                My research aims to enhance <strong>recommender systems</strong> by employing cutting-edge AI techniques, prioritizing critical challenges beyond accuracy, such as diversity, calibration, and fairness.
                Currently, I am developing fair and effective <strong>conversational recommender systems (CRS)</strong> using <strong>Large Language Models (LLMs)</strong>, aiming to deliver equitable and precise recommendations across diverse user groups.
<!--                <li><strong>Recommender Systems</strong></li>-->
<!--                Recommendation for action (CIKM'22), news (PAKDD'20, KAIS'21), and bundle (PLOS ONE'23)<br>-->
<!--                Diversified recommendation (PAKDD'23, PAKDD'23) and explainable recommendation (Arxiv'17)<br>-->
<!--                Cold-start recommendation and utilizing additional information (BigData'19)<br>-->
<!--                <li><strong>Graph Learning</strong></li>-->
<!--                Semi-supervised learning (IJCAI'19) and node-feature estimation (KDD'22)<br>-->
<!--                <li><strong>Transfer Learning</strong></li>-->
<!--                Multi-source domain adaptation (PLOS ONE'21, PLOS ONE'21)<br>-->
              </ul>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
              <ul>
                <li>[May. 2025] Our work on multimodal conversational recommendation has been accepted at <a href="https://kdd2025.kdd.org">KDD 2025</a>. Collaborating with a researcher from <a href="https://www.tri.global">Toyota Research</a> has been an amazing experience!</li></li>
                <li>[Jan. 2025] <a href="https://openai.com/form/researcher-access-program/">OpenAI</a> has supported our work on conversational recommendation by awarding us $1,000 in API credits.</li>
                <li>[Jul. 2024] Our work on conversational recommendation has been accepted for the short paper track at <a href="https://recsys.acm.org/recsys24/">RecSys 2024</a>. It has been an invaluable experience collaborating with the amazing team at <a href="https://research.netflix.com">Netflix Research</a>!</li>
                <li>[Jul. 2024] Our work on calibrated sequential recommendation has been accepted at <a href="https://cikm2024.org">CIKM 2024</a>.</li>
                <li>[Jan. 2024] Our work on cold-start bundle recommendation has been accepted at <a href="https://www2024.thewebconf.org">The Web Conference 2024</a>.</li>
<!--                <li>[Aug. 2023] I successfully defended my PhD thesis and received the <a href="https://cse.snu.ac.kr/community/news/1137?pageNum=4">Distinguished PhD Dissertation Award</a> from Seoul National University.</li>-->
<!--                <li>[May. 2023] I was honored to receive the Sejong Science Fellowship Grants under the Overseas Training Track. I plan to extend my research into the development of robust and interactive recommender systems.</li>-->
<!--                <li>[Feb. 2023] Our two works on diversified recommendation have been accepted at <a href="https://pakdd2023.org">PAKDD 2023</a>.</li>-->
<!--                <li>[Jan. 2023] Our work on bundle recommendation has been accepted at <a href="https://journals.plos.org/plosone/">PLOS ONE</a>.</li>-->
<!--                <li>[Aug. 2022] I won <a href="https://sigir.org/general-information/travel-grants/">SIGIR Student Travel Grant</a> for <a href="https://www.cikm2022.org">CIKM 2022</a> attendance.</li>-->
<!--                <li>[Aug. 2022] Our work on IoT recommendation was accepted at <a href="https://www.cikm2022.org">CIKM 2022</a>.</li>-->
<!--                <li>[May. 2022] Our work on feature estimation in graphs was accepted at <a href="https://kdd.org/kdd2022/">KDD 2022</a>.</li>-->
<!--                <li>[Oct. 2021] Our extending work on news recommendation was accepted at <a href="https://www.springer.com/journal/10115">KAIS</a>.</li>-->
<!--                <li>[Jul. 2021] Our work on multi-domain adaptation was accepted at <a href="https://journals.plos.org/plosone/">PLOS ONE</a>.</li>-->
<!--                <li>[Jun. 2021] Our work on multi-domain adaptation was accepted at <a href="https://journals.plos.org/plosone/">PLOS ONE</a>.</li>-->
<!--                <li>[Sep. 2020] We won the second prize award at <a href="https://msnews.github.io/competition.html">MIND News Recommendation Competition</a>, among 215 teams</li>-->
<!--                <li>[May. 2020] Our paper "Accurate News Recommendation Coalescing Personal and Global Temporal Preferences" won the best student award at <a href="https://pakdd.org">PAKDD</a> 2020.</li>-->
<!--                <li>[Feb. 2020] I won the <a href="https://humantech.samsung.com/saitext/index.jsp">Samsung HumanTech paper award</a>, honorable mention (4th in CSE).</li>-->
<!--                <li>[Jan. 2020] Our work on news recommendation was accepted at <a href="https://pakdd.org">PAKDD</a> 2020.</li>-->
<!--                <li>[Nov. 2019] I won Student Travel Award at <a href="https://bigdataieee.org">IEEE BigData</a> 2019.</li>-->
<!--                <li>[Oct. 2019] Our work on recommendation with additional information was accepted at <a href="https://bigdataieee.org">IEEE BigData</a> 2019.</li>-->
<!--                <li>[May. 2019] Our work on node classification in graphs was accepted at <a href="https://www.ijcai.org">IJCAI</a> 2019.</li>-->
              </ul>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:20px;width:0%;vertical-align:middle">
              <heading>Employment</heading>
                <tr>
                <td style="float:left;padding:10px;width:150px;margin-left:50px;vertical-align:middle"><img src="images/UCSD.png" width="100" height="100"></td>
                <td width="75%" valign="center">
                  <li><strong>University of California San Diego</strong>, California, United States</li>
                    Postdoctoral Researcher in <a href="https://cse.ucsd.edu">Computer Science and Engineering</a> (Sep. 2023 - Aug. 2025)<br>
                </td>
                </tr>
                <tr>
              <td style="float:left;padding:10px;width:150px;margin-left:50px;vertical-align:middle"><img src="images/Hyper.png" width="140" height="30"></td>
              <td width="75%" valign="center">
                <li><strong><a href="https://hyperconnect.com/en/">Hyperconnect</a></strong>, Seoul, South Korea</li>
                  Research Intern, Machine Learning Team (Jul. 2020 - Aug. 2020)
              </td>
              </tr>
              </td>
            </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:0%;vertical-align:middle">
              <heading>Education</heading>
              <tr>
              <td style="float:left;padding:10px;width:150px;margin-left:50px;vertical-align:middle"><img src="images/SNU.png" width="100" height="100"></td>
              <td width="75%" valign="center">
                <li><strong>Seoul National University</strong>, Seoul, South Korea</li>
                  Ph.D. in <a href="https://cse.snu.ac.kr/en/">Computer Science and Engineering</a> (Aug. 2023)<br>
                  M.Sc. in <a href="https://cse.snu.ac.kr/en/">Computer Science and Engineering</a> (Feb. 2019)
              </td>
              </tr>
              <tr>
              <td style="float:left;padding:10px;width:150px;margin-left:50px;vertical-align:middle"><img src="images/HYU.png" width="100" height="100"></td>
              <td width="75%" valign="center">
                <li><strong>Hanyang University</strong>, Seoul, South Korea</li>
                  B.Sc. in <a href="http://cs.hanyang.ac.kr/eng/">Computer Science and Engineering</a> (Feb. 2017)
              </td>
              </tr>
            </td>
          </tr>
        </tbody></table>

<!--        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>-->
<!--            <tr>-->
<!--            <td style="padding:20px;width:0%;vertical-align:middle">-->
<!--              <heading>Internship</heading>-->
<!--              <tr>-->
<!--              <td style="float:left;padding:10px;width:150px;margin-left:50px;vertical-align:middle"><img src="images/Hyper.png" width="130" height="25"></td>-->
<!--              <td width="75%" valign="center">-->
<!--                <li><strong><a href="https://hyperconnect.com/en/">Hyperconnect</a></strong>, Seoul, South Korea</li>-->
<!--                  Research Intern, Machine Learning Team (Jul. 2020 - Aug. 2020)-->
<!--              </td>-->
<!--              </tr>-->
<!--            </td>-->
<!--          </tr>-->
<!--        </tbody></table>-->

<!--        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>-->
<!--            <tr>-->
<!--            <td style="padding:20px;width:100%;vertical-align:middle">-->
<!--              <heading>Work Experience</heading>-->
<!--                <ul>-->
<!--                <li><strong><a href="https://hyperconnect.com/en/">Hyperconnect</a></strong>, Seoul, South Korea</li>-->
<!--                  Research Intern, Machine Learning team (Jul. 2020 - Aug. 2020)-->
<!--                </ul>-->
<!--            </td>-->
<!--          </tr>-->
<!--        </tbody></table>-->

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Awards and Grants</heading>
                <ul>
                  <li>[Jan. 2025] Awarded 1,000 USD API Credits for Research on Conversational Recommendation from <a href="https://openai.com/form/researcher-access-program/">OpenAI</a></li>
                  <li>[Aug. 2023] <a href="https://cse.snu.ac.kr/node/68332">Distinguished Ph.D. Dissertation Award</a> from Seoul National University</li>
                  <li>[May. 2023] Sejong Science Fellowship from <a href="https://www.nrf.re.kr/eng/main">National Research Foundation of Korea</a> (funding for 2 years postdoctoral research overseas)</li>
                  <li>[Aug. 2022] <a href="https://sigir.org/general-information/travel-grants/">SIGIR Student Travel Grant</a> for attending <a href="https://www.cikm2022.org">CIKM 2022</a></li>
                  <li>[Sep. 2020] <a href="https://msnews.github.io/competition.html">Microsoft Research MIND News Recommendation Competition Award</a> (2nd place among 215 teams)</li>
                    - <a href="https://msnews.github.io/assets/doc/2.pdf">Technical report</a><br>
                    - <a href="https://www.yna.co.kr/view/AKR20200928039700004">Press (in Korean)</a>
                  <li>[May. 2020] <a href="https://pakdd.org">PAKDD</a> Best Student Paper Award</li>
                    - <a href="https://www.newswire.co.kr/newsRead.php?no=905780">Press (in Korean)</a>
                  <li>[Feb. 2020] <a href="https://humantech.samsung.com/saitext/index.jsp">Samsung HumanTech Paper Award</a> (Honorable mention)</li>
                  <li>[Dec. 2019] <a href="https://bigdataieee.org">IEEE BigData</a> Student Travel Grant for attending <a href="http://bigdataieee.org/BigData2019/">BigData 2019</a></li>
                </ul>
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading2>2025</heading2>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/LaViC_fig.png" alt="clean-usnob" width="320" height="80">
            </td>
            <td width="75%" valign="middle">
              <papertitle>Adapting Large Vision-Language Models to Visually-Aware Conversational Recommendation</papertitle>
              <br>
              <u>Hyunsik Jeon</u>, Satoshi Koide, Yu Wang, Zhankui He, and Julian McAuley
              <br>
              <strong><em><a href="https://kdd2025.kdd.org">KDD 2025</a></em></strong>, Toronto, Ontario, Canada
              <br>
              [<a href="data/KDD25(LaViC).pdf">paper</a> / <a href="data/KDD25(LaViCSlides).pdf">slides</a> / <a href="data/KDD25(LaViCPoster).pdf">poster</a> / <a href="https://github.com/jeon185/LaViC">code</a> / <a href="data/jeon2025.bib">bib</a>]
              <br>
              <a href="javascript:void(0);" id="toggleLinkLaViC" onclick="toggleVisibility('moreInfoLaViC')">TL;DR</a>
              <div id="moreInfoLaViC" style="max-height: 0; overflow: hidden; transition: max-height 0.5s ease;">
                <span>Conversational recommender systems engage users in dialogues to refine their needs and provide more personalized suggestions. Although textual information suffices for many domains, visually driven categories potentially require detailed visual information. We propose LaViC, a novel approach for the visually-aware conversational recommendation.</span>
              </div>
            </td>
        </tr>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading2>2024</heading2>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/LeapRec_fig.png" alt="clean-usnob" width="320" height="120">
            </td>
            <td width="75%" valign="middle">
              <papertitle>Calibration-Disentangled Learning and Relevance-Prioritized Reranking for Calibrated Sequential Recommendation</papertitle>
              <br>
              <u>Hyunsik Jeon</u>, Se-eun Yoon, and Julian McAuley
              <br>
              <strong><em><a href="https://cikm2024.org">CIKM 2024</a></em></strong>, Boise, Idaho, USA
              <br>
              [<a href="data/CIKM24(LeapRec).pdf">paper</a> / <a href="data/CIKM24(LeapRecSlide).pdf">slides</a>  / <a href="https://github.com/jeon185/LeapRec">code</a> / <a href="data/jeon2024.bib">bib</a>]
              <br>
              <a href="javascript:void(0);" id="toggleLinkLeapRec" onclick="toggleVisibility('moreInfoLeapRec')">TL;DR</a>
              <div id="moreInfoLeapRec" style="max-height: 0; overflow: hidden; transition: max-height 0.5s ease;">
                <span>How can we reflect a balanced representation of user interests in sequential recommendations? We propose LeapRec which effectively combines model training with reranking to address the challenges of calibrating recommendations in a dynamic user preference environment.</span>
              </div>
            </td>
        </tr>

        <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/NBCRS_fig.png" alt="clean-usnob" width="320" height="140">
            </td>
            <td width="75%" valign="middle">
              <papertitle>Neighborhood-Based Collaborative Filtering for Conversational Recommendation</papertitle>
              <br>
              Zhouhang Xie*, Junda Wu*, <u>Hyunsik Jeon*</u>, Zhankui He, Harald Steck, Rahul Jha, Dawen Liang, Nathan Kallus, and Julian McAuley
              <br>
              <strong><em><a href="https://recsys.acm.org/recsys24/">RecSys 2024 - Short Paper</a></em></strong>, Bari, Italy
              <br>
              [<a href="data/RecSys(NBCRS).pdf">paper</a> / <a href="data/RecSys(NBCRSPoster).pdf">poster</a> / <a href="https://github.com/zhouhanxie/neighborhood-based-CF-for-CRS">code</a> / <a href="https://dblp.org/rec/conf/recsys/XieWJHSJLKM24.html?view=bibtex">bib</a>]
              <br>
              <a href="javascript:void(0);" id="toggleLinkNBCRS" onclick="toggleVisibility('moreInfoNBCRS')">TL;DR</a>
              <div id="moreInfoNBCRS" style="max-height: 0; overflow: hidden; transition: max-height 0.5s ease;">
                <span>How can we address conversational recommendations without relying on cumbersome external knowledge or extensive training of large language models? We propose NBCRS which utilizes neighborhood-based methods to provide effective and efficient conversational recommendations.</span>
              </div>
            </td>
        </tr>

        <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/CoHeat_fig.png" alt="clean-usnob" width="320" height="100">
            </td>
            <td width="75%" valign="middle">
              <papertitle>Cold-start Bundle Recommendation via Popularity-based Coalescence and Curriculum Heating</papertitle>
              <br>
              <u>Hyunsik Jeon</u>, Jong-eun Lee, Jeongin Yun, and U Kang
              <br>
              <strong><em><a href="https://www2024.thewebconf.org">WWW 2024</a></em></strong>, Singapore
              <br>
              <b><font color="#ff4500">Oral Presentation</font></b><br/>
              [<a href="data/WWW24(CoHeat).pdf">paper</a> / <a href="data/WWW24(CoHeatSlide).pdf">slides</a> / <a href="data/WWW24(CoHeatPoster).pdf">poster</a> / <a href="https://github.com/snudatalab/CoHeat">code</a> / <a href="https://dblp.org/rec/conf/www/JeonLYK24.html?view=bibtex">bib</a>]
              <br>
              <a href="javascript:void(0);" id="toggleLinkCoHeat" onclick="toggleVisibility('moreInfoCoHeat')">TL;DR</a>
              <div id="moreInfoCoHeat" style="max-height: 0; overflow: hidden; transition: max-height 0.5s ease;">
                <span>How can we accurately recommend cold-start bundles to users? We propose CoHeat which recommends cold-start bundles (as well as warm-start bundles), accurately.</span>
              </div>
            </td>
        </tr>


        <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/IaI_fig.pdf" alt="clean-usnob" width="320" height="200">
            </td>
            <td width="75%" valign="middle">
              <papertitle>Imagery as Inquiry: Exploring a Multimodal Dataset for Conversational Recommendation</papertitle>
              <br>
              Se-eun Yoon, <u>Hyunsik Jeon</u>, and Julian McAuley
              <br>
              <strong><em><a href="https://arxiv.org">arXiv</a> (2024)</em></strong>
              <br>
              [<a href="https://www.arxiv.org/pdf/2405.14142">paper</a>]
              <br>
              <a href="javascript:void(0);" id="toggleLinkIaI" onclick="toggleVisibility('moreInfoIaI')">TL;DR</a>
              <div id="moreInfoIaI" style="max-height: 0; overflow: hidden; transition: max-height 0.5s ease;">
                <span>We introduce a multimodal dataset where users express preferences through images.</span>
              </div>
            </td>
        </tr>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading2>2023</heading2>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/PopCon_fig.png" alt="clean-usnob" width="320" height="100">
            </td>
            <td width="75%" valign="middle">
              <papertitle>Aggregately Diversified Bundle Recommendation via Popularity Debiasing and Configuration-aware Reranking</papertitle>
              <br>
              <u>Hyunsik Jeon</u>, Jongjin Kim, Jaeri Lee, Jong-eun Lee, and U Kang
              <br>
              <strong><em><a href="https://pakdd2023.org">PAKDD 2023</a></em></strong>, Osaka, Japan
              <br>
              [<a href="data/PAKDD23(PopCon).pdf">paper</a> / <a href="data/PAKDD23(PopConSlide).pdf">slides</a> / <a href="https://github.com/snudatalab/PopCon">code</a> / <a href="https://dblp.org/rec/conf/pakdd/JeonKLLK23.html?view=bibtex">bib</a>]
              <br>
              <a href="javascript:void(0);" id="toggleLinkPopCon" onclick="toggleVisibility('moreInfoPopCon')">TL;DR</a>
              <div id="moreInfoPopCon" style="max-height: 0; overflow: hidden; transition: max-height 0.5s ease;">
                <span>How can we expose diverse items across all users while satisfying their needs in bundle recommendations? We propose PopCon which recommends top-k bundles to users, accurately and aggregately diversely.</span>
              </div>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DivMF_fig.png" alt="clean-usnob" width="320" height="130">
            </td>
            <td width="75%" valign="middle">
              <papertitle>Diversely Regularized Matrix Factorization for Accurate and Aggregately Diversified Recommendation</papertitle>
              <br>
              Jongjin Kim, <u>Hyunsik Jeon</u>, Jaeri Lee, and U Kang
              <br>
              <strong><em><a href="https://pakdd2023.org">PAKDD 2023</a></em></strong>, Osaka, Japan
              <br>
              [<a href="data/PAKDD23(DivMF).pdf">paper</a> / <a href="https://arxiv.org/pdf/2211.01328.pdf">arxiv</a> / <a href="https://github.com/snudatalab/DivMF">code</a> / <a href="https://dblp.org/rec/conf/pakdd/KimJLK23.html?view=bibtex">bib</a>]
              <br>
              <a href="javascript:void(0);" id="toggleLinkDivMF" onclick="toggleVisibility('moreInfoDivMF')">TL;DR</a>
              <div id="moreInfoDivMF" style="max-height: 0; overflow: hidden; transition: max-height 0.5s ease;">
                <span>When recommending personalized top-k items to users, how can we recommend the items diversely to them while satisfying their needs? We propose DivMF which recommends top-k items to users, accurately and aggregately diversely.</span>
              </div>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/BundleMage_fig.png" alt="clean-usnob" width="320" height="170">
            </td>
            <td width="75%" valign="middle">
              <papertitle>Accurate Bundle Matching and Generation via Multitask Learning with Partially Shared Parameters</papertitle>
              <br>
              <u>Hyunsik Jeon</u>, Jun-Gi Jang, Taehun Kim, and U Kang
              <br>
              <strong><em><a href="https://journals.plos.org/plosone/">PLOS ONE</a> (2023)</em></strong>
              <br>
              [<a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0280630">paper</a> / <a href="https://arxiv.org/pdf/2210.15460.pdf">arxiv</a> / <a href="https://github.com/snudatalab/BundleMage">code</a> / <a href="https://dblp.org/rec/journals/corr/abs-2210-15460.html?view=bibtex">bib</a>]
              <br>
              <a href="javascript:void(0);" id="toggleLinkBundleMage" onclick="toggleVisibility('moreInfoBundleMage')">TL;DR</a>
              <div id="moreInfoBundleMage" style="max-height: 0; overflow: hidden; transition: max-height 0.5s ease;">
                <span>Given item and bundle purchase histories of users, how can we match existing bundles to the users and generate new bundles for them? We propose BundleMage which matches existing bundles and generates personalized bundles simultaneously.</span>
              </div>
            </td>
          </tr>



          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading2>2022</heading2>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/SmartSense_fig.png" alt="clean-usnob" width="320" height="100">
            </td>
            <td width="75%" valign="middle">
              <papertitle>Accurate Action Recommendation for Smart Home via Two-Level Encoders and Commonsense Knowledge</papertitle>
              <br>
              <u>Hyunsik Jeon</u>, Jongjin Kim, Hoyoung Yoon, Jaeri Lee, and U Kang
              <br>
              <strong><em><a href="https://www.cikm2022.org">CIKM 2022</a></em></strong>, Atlanta, Georgia, USA
              <br>
              <b><font color="#ff4500">SIGIR Student Travel Grant</font></b><br/>
              [<a href="data/CIKM22(SmartSense).pdf">paper</a> / <a href="data/CIKM22(SmartSenseSlide).pdf">slides</a> / <a href="data/codes(SmartSense).zip">codes</a> / <a href="https://github.com/snudatalab/SmartSense">dataset</a> / <a href="https://dblp.org/rec/journals/corr/abs-2208-06089.html?view=bibtex">bib</a>]
              <br>
              <a href="javascript:void(0);" id="toggleLinkSmartSense" onclick="toggleVisibility('moreInfoSmartSense')">TL;DR</a>
              <div id="moreInfoSmartSense" style="max-height: 0; overflow: hidden; transition: max-height 0.5s ease;">
                <span>How can we accurately recommend actions for users to control their devices at home? We propose SmartSense which recommends device controls to users, accurately.</span>
              </div>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/SVGA_fig.png" alt="clean-usnob" width="320" height="100">
            </td>
            <td width="75%" valign="middle">
              <papertitle>Accurate Node Feature Estimation with Structured Variational Graph Autoencoder</papertitle>
              <br>
              Jaemin Yoo, <u>Hyunsik Jeon</u>, Jinhong Jung, and U Kang
              <br>
              <strong><em><a href="https://kdd.org/kdd2022/">KDD 2022</a></em></strong>, Washington D.C., USA
              <br>
              [<a href="https://arxiv.org/pdf/2206.04516.pdf">paper</a> / <a href="https://jaeminyoo.github.io/resources/slides/YooJJK22.pdf">slides</a> / <a href="https://github.com/snudatalab/SVGA">code</a> / <a href="https://dblp.uni-trier.de/rec/conf/kdd/YooJJK22.html?view=bibtex">bib</a>]
              <br>
              <a href="javascript:void(0);" id="toggleLinkSVGA" onclick="toggleVisibility('moreInfoSVGA')">TL;DR</a>
              <div id="moreInfoSVGA" style="max-height: 0; overflow: hidden; transition: max-height 0.5s ease;">
                <span>Given a graph with partial observations of node features, how can we estimate the missing features accurately? We propose SVGA which estimates the missing features of nodes, accurately.</span>
              </div>
            </td>
          </tr>


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading2>2021</heading2>
            </td>
          </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/PGT_J_fig.png" alt="clean-usnob" width="320" height="160">
            </td>
            <td width="75%" valign="middle">
              <papertitle>PGT: News Recommendation Coalescing Personal and Global Temporal Preferences</papertitle>
              <br>
              Bonhun Koo, <u>Hyunsik Jeon</u>, and U Kang
              <br>
              <strong><em><a href="https://www.springer.com/journal/10115">KAIS</a> (2021)</em></strong>
              <br>
              [<a href="https://link.springer.com/content/pdf/10.1007/s10115-021-01618-9.pdf">paper</a> / <a href="https://dblp.org/rec/journals/kais/KooJK21.html?view=bibtex">bib</a>]
              <br>
              <a href="javascript:void(0);" id="toggleLinkPGT_J" onclick="toggleVisibility('moreInfoPGT_J')">TL;DR</a>
              <div id="moreInfoPGT_J" style="max-height: 0; overflow: hidden; transition: max-height 0.5s ease;">
                <span>Given sequential news watch logs of users, how can we accurately recommend news articles? We propose PGT which recommends personalized news to the users, accurately.</span>
              </div>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/MultiEPL_fig.png" alt="clean-usnob" width="320" height="150">
            </td>
            <td width="75%" valign="middle">
              <papertitle>Multi-EPL: Accurate Multi-Source Domain Adaptation</papertitle>
              <br>
              Seongmin Lee, <u>Hyunsik Jeon</u>, and U Kang
              <br>
              <strong><em><a href="https://journals.plos.org/plosone/">PLOS ONE</a> (2021)</em></strong>
              <br>
              [<a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0255754">paper</a> / <a href="https://github.com/snudatalab/MultiEPL">code</a> / <a href="data/lee2021.bib">bib</a>]
              <br>
              <a href="javascript:void(0);" id="toggleLinkMultiEPL" onclick="toggleVisibility('moreInfoMultiEPL')">TL;DR</a>
              <div id="moreInfoMultiEPL" style="max-height: 0; overflow: hidden; transition: max-height 0.5s ease;">
                <span>Given multiple source datasets with labels, how can we train a target model with no labeled data? We propose Multi-EPL which accurately classifies the target dataset while utilizing multiple source datasets.</span>
              </div>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DEMS_fig.png" alt="clean-usnob" width="320" height="170">
            </td>
            <td width="75%" valign="middle">
              <papertitle>Unsupervised Multi-Source Domain Adaptation with No Observable Source Data</papertitle>
              <br>
              <u>Hyunsik Jeon</u>, Seongmin Lee, and U Kang
              <br>
              <strong><em><a href="https://journals.plos.org/plosone/">PLOS ONE</a> (2021)</em></strong>
              <br>
              [<a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0253415">paper</a> / <a href="https://github.com/snudatalab/DEMS">code</a> / <a href="data/jeon2021.html">bib</a>]
              <br>
              <a href="javascript:void(0);" id="toggleLinkDEMS" onclick="toggleVisibility('moreInfoDEMS')">TL;DR</a>
              <div id="moreInfoDEMS" style="max-height: 0; overflow: hidden; transition: max-height 0.5s ease;">
                <span>Given trained models from multiple source domains without any data, how can we predict the labels of unlabeled data in a target domain? We propose DEMS which adapts target data to source domains and accurately estimates the target labels, without exploiting any source data.</span>
              </div>
            </td>
          </tr>



          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading2>2020 and Before</heading2>
            </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/PGT_fig.png" alt="clean-usnob" width="320" height="170">
            </td>
            <td width="75%" valign="middle">
              <papertitle>Accurate News Recommendation Coalescing Personal and Global Temporal Preferences</papertitle>
              <br>
              Bonhun Koo, <u>Hyunsik Jeon</u>, and U Kang
              <br>
              <strong><em><a href="https://research.com/conference/pakdd-2020">PAKDD 2020</a></em></strong>, Singapore
              <br>
              <b><font color="#ff4500">Best Student Paper Award</font></b><br/>
              [<a href="https://datalab.snu.ac.kr/pgt/resources/pgt_pakdd2020.pdf">paper</a> / <a href="https://datalab.snu.ac.kr/pgt/">homepage</a> / <a href="https://dblp.org/rec/conf/pakdd/KooJK20.html?view=bibtex">bib</a>]
              <br>
              <a href="javascript:void(0);" id="toggleLinkPGT" onclick="toggleVisibility('moreInfoPGT')">TL;DR</a>
              <div id="moreInfoPGT" style="max-height: 0; overflow: hidden; transition: max-height 0.5s ease;">
                <span>Given session-based watch history of users, how can we precisely recommend new articles? We propose PGT which recommends news to the users, accurately.</span>
              </div>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DaConA_fig.png" alt="clean-usnob" width="320" height="150">
            </td>
            <td width="75%" valign="middle">
              <papertitle>Data Context Adaptation for Accurate Recommendation with Additional Information</papertitle>
              <br>
              <u>Hyunsik Jeon</u>, Bonhun Koo, and U Kang
              <br>
              <strong><em><a href="http://bigdataieee.org/BigData2019/">BigData 2019</a></em></strong>, Los Angeles, USA
              <br>
              <b><font color="#ff4500">Samsung HumanTech Paper Award, BigData Student Travel Grant</font></b><br/>
              [<a href="https://arxiv.org/pdf/1908.08469.pdf">paper</a> / <a href="https://datalab.snu.ac.kr/dacona/resources/slides.pdf">slides</a> / <a href="https://datalab.snu.ac.kr/dacona/">homepage</a> / <a href="https://dblp.org/rec/conf/bigdataconf/JeonKK19.html?view=bibtex">bib</a>]
              <br>
              <a href="javascript:void(0);" id="toggleLinkDaConA" onclick="toggleVisibility('moreInfoDaConA')">TL;DR</a>
              <div id="moreInfoDaConA" style="max-height: 0; overflow: hidden; transition: max-height 0.5s ease;">
                <span>Given a sparse rating matrix and an auxiliary matrix of users or items, how can we accurately predict missing ratings considering different data contexts of entities? We propose DaConA which accurately predicts ratings utilizing auxiliary matrix, based on neural networks.</span>
              </div>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/BPN_fig.png" alt="clean-usnob" width="320" height="180">
            </td>
            <td width="75%" valign="middle">
              <papertitle>Belief Propagation Network for Hard Inductive Semi-supervised Learning</papertitle>
              <br>
              Jaemin Yoo, <u>Hyunsik Jeon</u>, and U Kang
              <br>
              <strong><em><a href="https://www.ijcai19.org">IJCAI 2019</a></em></strong>, Macao, China
              <br>
              [<a href="https://www.ijcai.org/proceedings/2019/0580.pdf">paper</a> / <a href="https://jaeminyoo.github.io/resources/slides/YooJK19.pdf">slides</a> / <a href="https://jaeminyoo.github.io/resources/posters/JoYK18.pdf">poster</a> / <a href="https://github.com/snudatalab/BPN">code</a> / <a href="https://dblp.org/rec/conf/ijcai/YooJK19.html?view=bibtex">bib</a>]
              <br>
              <a href="javascript:void(0);" id="toggleLinkBPN" onclick="toggleVisibility('moreInfoBPN')">TL;DR</a>
              <div id="moreInfoBPN" style="max-height: 0; overflow: hidden; transition: max-height 0.5s ease;">
                <span>Given graph-structured data, how can we train a robust classifier in a semi-supervised setting that performs well without neighborhood information? We propose BPN which accurately classifies nodes in a hard inductive setting, based on a neural network.</span>
              </div>
            </td>
          </tr>

        <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/uniwalk_fig.png" alt="clean-usnob" width="320" height="100">
            </td>
            <td width="75%" valign="middle">
              <papertitle>UniWalk: Explainable and Accurate Recommendation for Rating and Network Data</papertitle>
              <br>
              Haekyu Park, <u>Hyunsik Jeon</u>, Junghwan Kim, Beunguk Ahn, and U Kang
              <br>
              <strong><em><a href="https://arxiv.org">arXiv</a> (2017)</em></strong>
              <br>
              [<a href="https://arxiv.org/pdf/1710.07134.pdf">arxiv</a> / <a href="https://datalab.snu.ac.kr/uniwalk/">homepage</a> / <a href="https://dblp.org/rec/journals/corr/abs-1710-07134.html?view=bibtex">bib</a>]
              <br>
              <a href="javascript:void(0);" id="toggleLinkuniwalk" onclick="toggleVisibility('moreInfouniwalk')">TL;DR</a>
              <div id="moreInfouniwalk" style="max-height: 0; overflow: hidden; transition: max-height 0.5s ease;">
                <span>Given a social network and ratings, how can we correctly recommend proper items and provide a persuasive explanation for the recommendation? We propose UniWalk which accurately recommends items and explains the reasons while exploiting both social network and rating data.</span>
              </div>
            </td>
          </tr>

        </tbody></table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Professional Services</heading>
              <ul>
                <li><strong>Session Chair</strong></li>
                <a href="http://www.cikmconference.org">CIKM</a> (2024)<br>
                <li><strong>Program Committee & Reviewer</strong></li>
                <a href="http://www.bigcomputing.org">BigComp</a> (2020 - 2023)<br>
                <a href="http://www.cikmconference.org">CIKM</a> (2018 - 2019)<br>
                <a href="https://icdm.zhonghuapu.com">ICDM</a> (2019)<br>
                <a href="https://iclr.cc">ICLR</a> (2021)<br>
                <a href="https://kdd.org/conferences">KDD</a> (2019 - 2025)<br>
                <a href="https://neurips.cc">NeurIPS</a> (2021 - 2023)<br>
                <a href="https://www.siam.org/conferences/cm/conference/sdm24">SDM</a> (2024 - 2025)<br>
                <a href="https://www.thewebconf.org">The Web Conference</a> (2019 - 2021, 2024 - 2025)<br>
                <a href="https://www.wsdm-conference.org">WSDM</a> (2019)<br>
                <li><strong>Journal Reviewer</strong></li>
                <a href="https://www.frontiersin.org/journals/big-data">Frontiers in Big Data</a> (2023 - 2024)
                <li><strong>PhD Symposium Mentorship</strong></li>
                <a href="http://www.cikmconference.org">CIKM</a> (2024)<br>
              </ul>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>


        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <a href="https://github.com/jonbarron/jonbarron_website">Template source</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>

<script>
function toggleVisibility(divId) {
    var info = document.getElementById(divId);
    var link = document.getElementById('toggleLink' + divId);
    if (info.style.maxHeight !== '100px') {
        info.style.maxHeight = '100px';
        link.textContent = 'Hide TL;DR';
        link.style.color = '#f09228';
    } else {
        info.style.maxHeight = '0';
        link.textContent = 'TL;DR';
        link.style.color = '#1772d0';
    }
}
</script>